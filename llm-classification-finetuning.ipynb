{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T09:14:32.777306Z","iopub.execute_input":"2025-01-05T09:14:32.777662Z","iopub.status.idle":"2025-01-05T09:14:33.145851Z","shell.execute_reply.started":"2025-01-05T09:14:32.777633Z","shell.execute_reply":"2025-01-05T09:14:33.144891Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntrain.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T09:14:36.823348Z","iopub.execute_input":"2025-01-05T09:14:36.823912Z","iopub.status.idle":"2025-01-05T09:14:39.334689Z","shell.execute_reply.started":"2025-01-05T09:14:36.823879Z","shell.execute_reply":"2025-01-05T09:14:39.333661Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def create_input_text(row):\n    return f\"<s>Prompt: {row['prompt']}</s><s>Option A: {row['response_a']}</s><s>Option B: {row['response_b']}</s>\"\n\n# Add special tokens to clearly delineate sections\ntrain[\"input_text\"] = train.apply(create_input_text, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n# Combine prompt and responses into a single input text\ntest[\"input_text\"] = test.apply(create_input_text, axis=1)\n\n# Print sample test data\nprint(test.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, f1_score\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\ndef prepare_input(row, tokenizer, max_length=512):\n    \"\"\"Prepare single input row for model\"\"\"\n    input_text = f\"<s>Prompt: {row['prompt']}</s><s>Option A: {row['response_a']}</s><s>Option B: {row['response_b']}</s>\"\n    \n    encoding = tokenizer(\n        input_text,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    input_dict = {\n        'input_ids': encoding['input_ids'].squeeze(),\n        'attention_mask': encoding['attention_mask'].squeeze(),\n    }\n    \n    if 'winner_model_a' in row:\n        input_dict['target'] = torch.tensor([\n            row['winner_model_a'],\n            row['winner_model_a'],\n            row['winner_tie']\n        ], dtype=torch.float)\n    \n    return input_dict\n\ndef create_dataloader(df, tokenizer, batch_size=16, shuffle=True):\n    \"\"\"Create dataloader from dataframe\"\"\"\n    dataset = [prepare_input(row, tokenizer) for _, row in df.iterrows()]\n    \n    # Collate function to handle batching\n    def collate_fn(batch):\n        input_ids = torch.stack([item['input_ids'] for item in batch])\n        attention_mask = torch.stack([item['attention_mask'] for item in batch])\n        \n        if 'target' in batch[0]:\n            targets = torch.stack([item['target'] for item in batch])\n            return {\n                'input_ids': input_ids,\n                'attention_mask': attention_mask,\n                'target': targets\n            }\n        \n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask\n        }\n    \n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n\ndef augment_data(df):\n    \"\"\"Augment training data by swapping responses\"\"\"\n    augmented_rows = []\n    \n    for _, row in df.iterrows():\n        # Original row\n        augmented_rows.append({\n            'prompt': row['prompt'],\n            'response_a': row['response_a'],\n            'response_b': row['response_b'],\n            'winner_model_a': row['winner_model_a'],\n            'winner_model_b': row['winner_model_b'],\n            'winner_tie': row['winner_tie']\n        })\n        \n        # Swapped version\n        augmented_rows.append({\n            'prompt': row['prompt'],\n            'response_a': row['response_b'],\n            'response_b': row['response_a'],\n            'winner_model_a': row['winner_model_b'],\n            'winner_model_b': row['winner_model_a'],\n            'winner_tie': row['winner_tie']\n        })\n    \n    return pd.DataFrame(augmented_rows)\n\ndef create_model(model_name='roberta-base'):\n    \"\"\"Create model with custom head\"\"\"\n    roberta = RobertaModel.from_pretrained(model_name)\n    \n    # Add custom layers\n    attention_pooling = nn.Sequential(\n        nn.Linear(768, 1),\n        nn.Softmax(dim=1)\n    )\n    \n    classifier = nn.Sequential(\n        nn.Linear(768, 512),\n        nn.LayerNorm(512),\n        nn.Dropout(0.1),\n        nn.ReLU(),\n        nn.Linear(512, 128),\n        nn.LayerNorm(128),\n        nn.Dropout(0.1),\n        nn.ReLU(),\n        nn.Linear(128, 3)\n    )\n    \n    return roberta, attention_pooling, classifier\n\ndef forward_pass(batch, roberta, attention_pooling, classifier, device):\n    \"\"\"Forward pass through the model\"\"\"\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    \n    outputs = roberta(input_ids, attention_mask=attention_mask)\n    hidden_states = outputs.last_hidden_state\n    \n    # Attention pooling\n    attention_weights = attention_pooling(hidden_states)\n    pooled = torch.sum(attention_weights * hidden_states, dim=1)\n    \n    # Classification\n    logits = classifier(pooled)\n    return torch.softmax(logits, dim=1)\n\ndef compute_loss(predictions, targets):\n    \"\"\"Compute loss with label smoothing\"\"\"\n    targets = targets * 0.9 + 0.033  # Label smoothing\n    loss = -torch.sum(targets * torch.log(predictions + 1e-7), dim=1)\n    return loss.mean()\n\ndef train_epoch(train_loader, roberta, attention_pooling, classifier, optimizer, scheduler, device):\n    \"\"\"Train for one epoch\"\"\"\n    roberta.train()\n    attention_pooling.train()\n    classifier.train()\n    \n    total_loss = 0\n    progress_bar = tqdm(train_loader, desc='Training')\n    \n    for batch in progress_bar:\n        outputs = forward_pass(batch, roberta, attention_pooling, classifier, device)\n        targets = batch['target'].to(device)\n        \n        loss = compute_loss(outputs, targets)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(roberta.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        \n        total_loss += loss.item()\n        progress_bar.set_postfix({'loss': f'{total_loss/len(train_loader):.3f}'})\n    \n    return total_loss / len(train_loader)\n\ndef evaluate(val_loader, roberta, attention_pooling, classifier, device):\n    \"\"\"Evaluate model\"\"\"\n    roberta.eval()\n    attention_pooling.eval()\n    classifier.eval()\n    \n    predictions = []\n    targets = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            outputs = forward_pass(batch, roberta, attention_pooling, classifier, device)\n            predictions.extend(outputs.cpu().numpy())\n            targets.extend(batch['target'].numpy())\n    \n    predictions = np.array(predictions)\n    targets = np.array(targets)\n    \n    pred_labels = np.argmax(predictions, axis=1)\n    target_labels = np.argmax(targets, axis=1)\n    \n    return {\n        'accuracy': accuracy_score(target_labels, pred_labels),\n        'f1': f1_score(target_labels, pred_labels, average='weighted')\n    }\n\ndef predict(test_loader, roberta, attention_pooling, classifier, device):\n    \"\"\"Generate predictions for test data\"\"\"\n    roberta.eval()\n    attention_pooling.eval()\n    classifier.eval()\n    \n    predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc='Predicting'):\n            outputs = forward_pass(batch, roberta, attention_pooling, classifier, device)\n            predictions.extend(outputs.cpu().numpy())\n    \n    return np.array(predictions)\n\ndef train_model(train_loader, val_loader, device, num_epochs=3):\n    \"\"\"Main training function\"\"\"\n    roberta, attention_pooling, classifier = create_model()\n    roberta = roberta.to(device)\n    attention_pooling = attention_pooling.to(device)\n    classifier = classifier.to(device)\n    \n    # Optimizer\n    optimizer = torch.optim.AdamW([\n        {'params': roberta.parameters(), 'lr': 2e-5},\n        {'params': attention_pooling.parameters(), 'lr': 1e-4},\n        {'params': classifier.parameters(), 'lr': 1e-4}\n    ])\n    \n    # Scheduler\n    num_training_steps = len(train_loader) * num_epochs\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=num_training_steps * 0.1,\n        num_training_steps=num_training_steps\n    )\n    \n    best_f1 = 0\n    best_state = None\n    \n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n        \n        train_loss = train_epoch(\n            train_loader, roberta, attention_pooling, classifier,\n            optimizer, scheduler, device\n        )\n        \n        metrics = evaluate(val_loader, roberta, attention_pooling, classifier, device)\n        print(f'Validation Accuracy: {metrics[\"accuracy\"]:.3f}')\n        print(f'Validation F1: {metrics[\"f1\"]:.3f}')\n        \n        if metrics['f1'] > best_f1:\n            best_f1 = metrics['f1']\n            best_state = {\n                'roberta': roberta.state_dict(),\n                'attention_pooling': attention_pooling.state_dict(),\n                'classifier': classifier.state_dict()\n            }\n    \n    return best_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T09:14:43.694747Z","iopub.execute_input":"2025-01-05T09:14:43.695161Z","iopub.status.idle":"2025-01-05T09:14:48.500465Z","shell.execute_reply.started":"2025-01-05T09:14:43.695095Z","shell.execute_reply":"2025-01-05T09:14:48.499408Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n\n# Augment training data\ntrain_df = augment_data(train)\n\n# Create dataloaders\ntrain_loader = create_dataloader(train_df, tokenizer, batch_size=16, shuffle=True)\ntest_loader = create_dataloader(test, tokenizer, batch_size=32, shuffle=False)\n\n# Train model\nbest_state = train_model(train_loader, train_loader, device)  # Using train as validation for example\n\n# Load best model\nroberta, attention_pooling, classifier = create_model()\nroberta.load_state_dict(best_state['roberta'])\nattention_pooling.load_state_dict(best_state['attention_pooling'])\nclassifier.load_state_dict(best_state['classifier'])\n    \nroberta = roberta.to(device)\nattention_pooling = attention_pooling.to(device)\nclassifier = classifier.to(device)\n\n# Generate predictions\npredictions = predict(test_loader, roberta, attention_pooling, classifier, device)\npred_labels = np.argmax(predictions, axis=1)\n\n# Create submission\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'prediction': ['a' if p == 0 else 'b' if p == 1 else 'tie' for p in pred_labels]\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T09:14:50.893614Z","iopub.execute_input":"2025-01-05T09:14:50.894277Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|â–Œ         | 403/7185 [5:05:43<88:08:28, 46.79s/it, loss=0.062]","output_type":"stream"}],"execution_count":null}]}